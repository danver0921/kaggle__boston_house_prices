{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    X = df.drop(columns=['MEDV'])\n",
    "    Y = df['MEDV']\n",
    "    return X, Y\n",
    "\n",
    "# 데이터 읽기\n",
    "data = pd.read_csv('data/train.csv').set_index('ID')\n",
    "input_x, input_y = extract(data.drop(columns=['CHAS', 'RAD']))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in data.items():\n",
    "    sns.boxplot(y=k, data=data, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in input_x.items():\n",
    "    q1 = v.quantile(0.25)\n",
    "    q3 = v.quantile(0.75)\n",
    "    irq = q3 - q1\n",
    "    v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n",
    "    perc = np.shape(v_col)[0] * 100.0 / np.shape(data)[0]\n",
    "    print(\"Column %s outliers = %.2f%%\" % (k, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in data.items():\n",
    "    sns.distplot(v, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(data.corr().abs(),  annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Let's scale the columns before plotting them against MEDV\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "column_sels = ['LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE']\n",
    "x = data.loc[:,column_sels]\n",
    "y = data['MEDV']\n",
    "x = pd.DataFrame(data=min_max_scaler.fit_transform(x), columns=column_sels)\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for i, k in enumerate(column_sels):\n",
    "    sns.regplot(y=y, x=x[k], ax=axs[i])\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  np.log1p(y)\n",
    "for col in x.columns:\n",
    "    if np.abs(x[col].skew()) > 0.3:\n",
    "        x[col] = np.log1p(x[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "l_regression = linear_model.LinearRegression()\n",
    "kf = KFold(n_splits=10)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scores = cross_val_score(l_regression, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores_map = {}\n",
    "scores_map['LinearRegression'] = scores\n",
    "l_ridge = linear_model.Ridge()\n",
    "scores = cross_val_score(l_ridge, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['Ridge'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Lets try polinomial regression with L2 with degree for the best fit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#for degree in range(2, 6):\n",
    "#    model = make_pipeline(PolynomialFeatures(degree=degree), linear_model.Ridge())\n",
    "#    scores = cross_val_score(model, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "#    print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "model = make_pipeline(PolynomialFeatures(degree=3), linear_model.Ridge())\n",
    "scores = cross_val_score(model, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['PolyRidge'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "#grid_sv = GridSearchCV(svr_rbf, cv=kf, param_grid={\"C\": [1e0, 1e1, 1e2, 1e3], \"gamma\": np.logspace(-2, 2, 5)}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "scores = cross_val_score(svr_rbf, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['SVR'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "desc_tr = DecisionTreeRegressor(max_depth=5)\n",
    "#grid_sv = GridSearchCV(desc_tr, cv=kf, param_grid={\"max_depth\" : [1, 2, 3, 4, 5, 6, 7]}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "scores = cross_val_score(desc_tr, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['DecisionTreeRegressor'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=7)\n",
    "scores = cross_val_score(knn, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['KNeighborsRegressor'] = scores\n",
    "#grid_sv = GridSearchCV(knn, cv=kf, param_grid={\"n_neighbors\" : [2, 3, 4, 5, 6, 7]}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "print(\"KNN Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(alpha=0.9,learning_rate=0.05, max_depth=2, min_samples_leaf=5, min_samples_split=2, n_estimators=100, random_state=30)\n",
    "#param_grid={'n_estimators':[100, 200], 'learning_rate': [0.1,0.05,0.02], 'max_depth':[2, 4,6], 'min_samples_leaf':[3,5,9]}\n",
    "#grid_sv = GridSearchCV(gbr, cv=kf, param_grid=param_grid, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "scores = cross_val_score(gbr, x_scaled, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_map['GradientBoostingRegressor'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "scores_map = pd.DataFrame(scores_map)\n",
    "sns.boxplot(data=scores_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
